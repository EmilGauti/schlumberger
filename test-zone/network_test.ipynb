{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from load_data import load_images, CustomTensorDataset\n",
    "from load_data_simulated import load_synth_images\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms       \n",
    "#init_transforms = transforms.Compose([transforms.CenterCrop(128)])\n",
    "init_transforms = transforms.Compose([transforms.Resize((128,128))])#,transforms.Normalize([0.5],[0.5])])\n",
    "init_transforms_target = transforms.Resize((128,128))\n",
    "\n",
    "#tensor_x, tensor_y, tensor_x_test, tensor_y_test = load_images()\n",
    "tensor_x, tensor_y = load_images()\n",
    "tensor_x_sim, tensor_y_sim = load_synth_images()\n",
    "\n",
    "tensor_x_val =   tensor_x[:30]/255\n",
    "tensor_y_val =   tensor_y[:30]/255\n",
    "tensor_x =       tensor_x[30:]/255\n",
    "tensor_y =       tensor_y[30:]/255\n",
    "tensor_x_sim = init_transforms(tensor_x_sim/255)\n",
    "tensor_y_sim = init_transforms(tensor_y_sim/255)\n",
    "print(tensor_x_sim.shape)\n",
    "\n",
    "print(tensor_x.shape)\n",
    "tensor_x = init_transforms(tensor_x) #/255\n",
    "tensor_y = init_transforms_target(tensor_y) #/255\n",
    "print(tensor_x.shape)\n",
    "tensor_x = torch.cat((tensor_x,tensor_x_sim))\n",
    "tensor_y = torch.cat((tensor_y,tensor_y_sim))\n",
    "tensor_x = tensor_x[:32]\n",
    "tensor_y = tensor_y[:32]\n",
    "tensor_x_val = init_transforms(tensor_x_val) #/255\n",
    "tensor_y_val = init_transforms_target(tensor_y_val) #/255\n",
    "#tensor_x_test = init_transforms(tensor_x_test) /255\n",
    "#tensor_y_test = init_transforms(tensor_y_test) /255\n",
    "print(tensor_x.shape)\n",
    "\n",
    "\n",
    "#my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "\n",
    "my_dataset = CustomTensorDataset(tensors=(tensor_x,tensor_y),transform=True,hflip_p=0.5,vflip_p=0.5)\n",
    "#my_dataset_test = TensorDataset(tensor_x_test,tensor_y_test) # create your datset\n",
    "my_dataset_val = TensorDataset(tensor_x_val,tensor_y_val)\n",
    "\n",
    "my_dataloader = DataLoader(my_dataset,shuffle=True,batch_size=2)#, batch_size=1) # create your dataloader\n",
    "#my_dataloader_test = DataLoader(my_dataset_test)\n",
    "my_dataloader_val = DataLoader(my_dataset_val)\n",
    "print(len(my_dataloader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_transform = transforms.ToPILImage()\n",
    "#a_transform(tensor_x[-4,:,:]).show()\n",
    "#a_transform(tensor_y[-4,:,:]).show()\n",
    "#tensor_y_test.shape\n",
    "\n",
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "#from DNNs import BasicNet_old as Net# Load the wanted network from the DNNs.py file\n",
    "from csnet import CSNet as Net\n",
    "#from U_Net import UNet as Net\n",
    "\n",
    "#my_nn = Net().to(device=device)\n",
    "#my_nn = Net().to(device=device)\n",
    "my_nn = Net(classes=1,channels=1).to(device=device)\n",
    "#summary(my_nn,(5,1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACCURACY FUNCTION\n",
    "#SÃ¶rensen-Dice\n",
    "from sklearn.metrics import f1_score\n",
    "def f1(my_nn,my_dataloader):\n",
    "    with torch.no_grad():\n",
    "        totalScore = 0\n",
    "        for i,(x_test,y_test) in enumerate(my_dataloader):\n",
    "            x_test = x_test.to(device=device)\n",
    "            y_test = y_test.to(device=device)\n",
    "            x_test = torch.unsqueeze(x_test,1)\n",
    "            y_pred = my_nn.forward(x_test)\n",
    "            y_pred = torch.squeeze(y_pred)\n",
    "            y_pred = y_pred.flatten()\n",
    "            target = y_test\n",
    "            target = torch.squeeze(target)\n",
    "            target = target.flatten()\n",
    "            target = target.cpu().detach().numpy()\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "            y_pred = convToBinary(y_pred)\n",
    "            target = convToBinary(target)\n",
    "\n",
    "            score = f1_score(target,y_pred,average=\"binary\")\n",
    "            #print(score)\n",
    "            totalScore = totalScore + score\n",
    "        N=len(my_dataloader.dataset)\n",
    "        return totalScore/N\n",
    "        #print(\"TotalScore: \",totalScore/N)\n",
    "def test_acc(my_nn,my_dataloader):\n",
    "    with torch.no_grad():\n",
    "        accuracy=0\n",
    "        N = len(my_dataloader.dataset)\n",
    "        for i,(x_test,y_test) in enumerate(my_dataloader):\n",
    "            if len(x_test.shape)==3:\n",
    "                x_test = torch.unsqueeze(x_test, 0)\n",
    "            x_test = x_test.to(device=device)\n",
    "            y_test = y_test.to(device=device)\n",
    "            y_pred = my_nn.forward(x_test)\n",
    "            target = y_test.cpu().detach().numpy()\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "            y_pred = convToBinary(y_pred)\n",
    "            accuracy = accuracy + acc(y_pred,target)\n",
    "        return 1-accuracy/N\n",
    "def convToBinary(output):\n",
    "    binary_output=np.zeros_like(output)\n",
    "    binary_output[output>0.5] = 1\n",
    "    return binary_output\n",
    "def acc(output,target):\n",
    "    return ((output-target)**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def base_pic(my_nn):\n",
    "    convert_tensor = transforms.PILToTensor()\n",
    "    init_trans = transforms.Compose([transforms.Resize((128,128))])\n",
    "    image = Image.open(\"../data_seismic/sample2.png\").convert('L')\n",
    "    #image = Image.open(\"../WestCam/images_for_training/239.png\").convert('L')\n",
    "    #image = Image.open(\"simulated_data/Test/40_png.png\").convert('L')\n",
    "    image = convert_tensor(image)\n",
    "\n",
    "    image = init_trans(image)/255\n",
    "    #print(image.shape)\n",
    "    y_pred = my_nn.forward(image)\n",
    "    y_pred=y_pred.detach().numpy()\n",
    "    y_pred=convToBinary(y_pred)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image[0,:,:],cmap=\"gray\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(y_pred[0,:,:],cmap=\"gray\")\n",
    "    plt.show()\n",
    "#base_pic(my_nn.to(device=\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot from val/test tensor\n",
    "from PIL import Image\n",
    "def generate_pic(my_nn,tensor_x_val,tensor_y_val,im_nr=25):\n",
    "    image = tensor_x_val[im_nr,:,:]\n",
    "    \n",
    "    image = torch.unsqueeze(image,0)\n",
    "    image = torch.unsqueeze(image,0)\n",
    "    \n",
    "    image_target = tensor_y_val[im_nr,:,:]\n",
    "    y_pred = my_nn.forward(image)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    y_pred=y_pred.detach().numpy()\n",
    "    image_target = image_target.detach().numpy()\n",
    "    image =torch.squeeze(image)\n",
    "    image = image.detach().numpy()\n",
    "    y_pred=convToBinary(y_pred)\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(image,cmap=\"gray\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(image_target,cmap=\"gray\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(y_pred,cmap=\"gray\")\n",
    "    plt.show()\n",
    "#my_loaded_network = Net()\n",
    "#my_loaded_network.load_state_dict(torch.load(\"models/model_12\"))\n",
    "generate_pic(my_nn.to(device=\"cpu\"),tensor_x_val,tensor_y_val,im_nr=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/Emil_CSNet\")\n",
    "# Set the value DEBUG variable\n",
    "os.environ.setdefault('PYTORCH_ENABLE_MPS_FALLBACK', \"1\")\n",
    "costval = []\n",
    "test_accuracy_list =[]\n",
    "f1_scores = []\n",
    "#my_nn = Net().to(device=device)\n",
    "my_nn = Net(channels=1,classes=1).to(device=device)\n",
    "#mps_device=torch.device(\"mps\")\n",
    "#my_nn.to(mps_device)\n",
    "criterion = nn.BCELoss()\n",
    "criterion2 = nn.\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(my_nn.parameters())#,lr=0.01)#,weight_decay=1e-5)#,lr=0.01)\n",
    "\n",
    "epochs=400\n",
    "start=0\n",
    "count=0\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for j in range(start,start+epochs):\n",
    "  print(j,\"-------------------------------------------------\")\n",
    "  my_nn.train()\n",
    "  for i,(x_train,y_train) in enumerate(my_dataloader):\n",
    "    x_train = x_train.to(device=device)\n",
    "    y_train = y_train.to(device=device)\n",
    "    x_train = torch.unsqueeze(x_train,1)\n",
    "    y_pred = my_nn.forward(x_train).to(device=device)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    #print(y_train.shape,y_pred.shape)\n",
    "    cost = criterion(y_pred,y_train)\n",
    "    #print(cost)\n",
    "    writer.add_scalar(\"train/cost\", cost, count)\n",
    "    count+=1\n",
    "\n",
    "    #backprop\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "  my_nn.eval()\n",
    "  #costval.append(cost)\n",
    "  #print(cost)\n",
    "  torch.save(my_nn.state_dict(),\"models/model_\"+str(j))\n",
    "  accuracy=test_acc(my_nn,my_dataloader_val)\n",
    "  f1_s = f1(my_nn,my_dataloader_val)\n",
    "  print(\"cost,MSE,F1:\",cost,accuracy,f1_s)\n",
    "  writer.add_scalar(\"val/accuracy\", accuracy, j)\n",
    "  writer.add_scalar(\"val/f1\", f1_s, j)\n",
    "  #costval.append(cost)\n",
    "  #test_accuracy_list.append(accuracy)\n",
    "  #f1_scores.append(f1_s)\n",
    "  generate_pic(my_nn.to(device=\"cpu\"),tensor_x_val,tensor_y_val,im_nr=25)\n",
    "  my_nn.to(device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e24872bbadec83121d90e49917c94df6eaccc621450d018ec121c7e73787fa28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
